# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W4sYDhoRgENR1rxJ0oe2z-3VPpkZGqad
"""

import torch
from torchvision import transforms
import torch.optim as optim
import torch.nn.functional as F



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
from PIL import Image
import torch.nn as nn

from torch.utils.data import Dataset, DataLoader

#directory - it contains a folder "Images" with jpg format images and a folder "Labels" with a csv file of labels
root_dir = "/users/hi3001" 
BATCH_SIZE = 8
EPOCHS = 10
LR = 0.003
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

ENCODER = 'timm-efficientnet-b0'
WEIGHTS = 'imagenet'

class HiDefDataset(Dataset)
    def __init__(self, root_dir, transform=None ):
        """
        Args:
            root_dir (string): Directory with 'Images' and 'Labels' folders.
            transform (callable, optional): Optional transform to be applied
                on an image sample.
        """
        #self.images_dir = os.path.join(root_dir, 'Images')
        self.images_dir = os.path.join(root_dir)
        self.labels_path = os.path.join(root_dir, 'Labels', 'Compiled_Data.csv')
        self.labels_df = pd.read_csv(self.labels_path, delimiter=",", quotechar='"')  # Read labels CSV into a DataFrame

        if transform:
            self.transform = transform
        else:
            self.transform = transforms.Compose([
                transforms.Resize((256, 256)),     # Resize to 256x256
                transforms.ToTensor()              # Convert to Tensor
            ])

        # List of label columns to retrieve
        self.label_columns = [
            "Guillemot", "Razorbill", "Guillemot/Razorbill", "Puffin",
            "Auk Species", "Gannet", "Kittiwake", "Fulmar",
            "Gull Species", "Cormorant", "Shag", "Cormorant/Shag",
            "Unknown/Other Bird Species"
        ]

    def __len__(self):
        # Returns the number of images
        return len(self.labels_df)

    def __getitem__(self, idx):
        # Get the image name and label from the specified columns
        img_name = self.labels_df.loc[idx, "Photo"]
        img_sub_path = self.labels_df.loc[idx, "Directory"]
        #img_path = os.path.join(self.images_dir, img_name)
        img_path = os.path.join(self.images_dir, img_sub_path, img_name)

        # Extract the labels as a tensor or list
        labels = self.labels_df.iloc[idx][self.label_columns].values.astype(float)
        labels = torch.tensor(labels, dtype=torch.float32)  # Convert to float tensor
        
        # Load the image
        image = Image.open(img_path).convert("RGB")

        #Apply (optional) transformations
        image = self.transform(image)  # Apply the resizing and tensor conversion

        return image, labels

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

transform = transforms.Compose([
                transforms.Resize((640, 640)),     # Resize to 256x256
                transforms.RandomHorizontalFlip(p=0.5), # Apply vertical flip with 50% probability
                transforms.ColorJitter(                 # Apply random color adjustments
                    brightness=0.2,                    # Randomly change brightness
                    contrast=0.2,                      # Randomly change contrast
                    saturation=0.2,                    # Randomly change saturation
                    hue=0.1                            # Randomly change hue
                ),
                transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # Apply Gaussian blur
                transforms.RandomEqualize(p=0.5),       # Apply histogram equalization with 50% probability
                transforms.RandomRotation(degrees=15), # Apply random rotation within Â±15 degrees
                transforms.ToTensor()              # Convert to Tensor (scales to [0, 1])
            ])

train_dataset = HiDefDataset(root_dir=root_dir, transform = transform)

# Access a sample
image, label = train_dataset[0]
print("Image shape:", image.shape)
print("Label:", label)

import matplotlib.pyplot as plt
import torchvision.transforms as transforms
import torch

# Assuming `image_tensor` is the tensor with shape (3, M, N)
def show_image(image_tensor):
    # Convert tensor to (M, N, 3) format and back to the range [0, 255] for visualization
    image = image_tensor.permute(1, 2, 0)  # Move channels to the last dimension
    image = image * 255  # Scale back to [0, 255]
    image = image.type(torch.uint8)  # Convert to integer type

    # Convert to NumPy array for displaying with matplotlib
    image_np = image.numpy()

    # Display the image
    plt.imshow(image_np)
    plt.axis('off')  # Hide axes
    plt.show()

show_image(image)

full_dataset = HiDefDataset(root_dir=root_dir, transform = transform)

train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [0.5, 0.5])

BATCH_SIZE = 2

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

class ConvReLU(nn.Module):
    def __init__(self, in_c, out_c, kernel_size=3, padding=1) -> None:
        super(ConvReLU, self).__init__()
        self.conv = nn.Conv2d(in_c, out_c, kernel_size=kernel_size, padding=padding)
        self.bn = nn.BatchNorm2d(out_c)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.relu(x)
        return x

class EncoderBlock(nn.Module):
    def __init__(self, in_c, out_c, depth=2, kernel_size=3, padding=1) -> None:
        super(EncoderBlock, self).__init__()
        self.layers = nn.ModuleList()
        for i in range(depth):
            self.layers.append(ConvReLU(in_c if i == 0 else out_c, out_c, kernel_size, padding))
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)

    def forward(self, x):
        for layer in self.layers:
            x = layer(x)
        x, ind = self.pool(x)
        return x, ind

class DecoderBlock(nn.Module):
    def __init__(self, in_c, out_c, depth=2, kernel_size=3, padding=1, classification=False) -> None:
        super(DecoderBlock, self).__init__()
        self.unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)
        self.layers = nn.ModuleList()
        for i in range(depth):
            if i == depth - 1 and classification:
                self.layers.append(nn.Conv2d(in_c, out_c, kernel_size=kernel_size, padding=padding))
            elif i == depth - 1:
                self.layers.append(ConvReLU(in_c, out_c, kernel_size=kernel_size, padding=padding))
            else:
                self.layers.append(ConvReLU(in_c, in_c, kernel_size=kernel_size, padding=padding))

    def forward(self, x, ind):
        x = self.unpool(x, ind)
        for layer in self.layers:
            x = layer(x)
        return x

class SegNet(nn.Module):
    def __init__(self, in_channels=3, out_channels=1, features=64, num_classes=13) -> None:
        super(SegNet, self).__init__()

        # Encoder
        self.enc0 = EncoderBlock(in_channels, features)
        self.enc1 = EncoderBlock(features, features * 2)
        self.enc2 = EncoderBlock(features * 2, features * 4, depth=3)
        self.enc3 = EncoderBlock(features * 4, features * 8, depth=3)

        # Bottleneck
        self.bottleneck_enc = EncoderBlock(features * 8, features * 8, depth=3)
        self.bottleneck_dec = DecoderBlock(features * 8, features * 8, depth=3)

        # Decoder
        self.dec0 = DecoderBlock(features * 8, features * 4, depth=3)
        self.dec1 = DecoderBlock(features * 4, features * 2, depth=3)
        self.dec2 = DecoderBlock(features * 2, features)
        self.dec3 = DecoderBlock(features, out_channels, classification=True)  # No activation

        # Additional layer for 13-dimensional vector output
        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)  # Pool to 1x1 spatial dimensions
        self.linear = nn.Linear(features * 8, num_classes)  # Fully connected layer

    def forward(self, x):
        # Encoder
        e0, ind0 = self.enc0(x)
        e1, ind1 = self.enc1(e0)
        e2, ind2 = self.enc2(e1)
        e3, ind3 = self.enc3(e2)

        # Bottleneck
        b0, indb = self.bottleneck_enc(e3)
        b1 = self.bottleneck_dec(b0, indb)

        # Decoder
        d0 = self.dec0(b1, ind3)
        d1 = self.dec1(d0, ind2)
        d2 = self.dec2(d1, ind1)

        # Classification layer for segmentation
        segmentation_output = self.dec3(d2, ind0)

        # Global average pooling and fully connected layer for 13-dimensional vector
        pooled_features = self.global_avg_pool(b1)  # Shape: [batch_size, features*8, 1, 1]
        flattened_features = pooled_features.view(pooled_features.size(0), -1)  # Flatten: [batch_size, features*8]
        class_vector = self.linear(flattened_features)  # Shape: [batch_size, num_classes]

        return class_vector

model_simple = SegNet()
model_simple.to(DEVICE)

# Example Input
input_tensor = torch.rand(1, 3, 640, 640)  # Dummy input tensor
#input_tensor = input_tensor.to(DEVICE)

# Forward Pass
class_counts = model_simple(input_tensor)
print(class_counts, class_counts.shape)

criterion = nn.CrossEntropyLoss()  # For multi-class classification
optimizer = optim.Adam(model_simple.parameters(), lr=0.001)

print('Start training!')

# Training loop
num_epochs = 5
for epoch in range(num_epochs):
    model_simple.train()  # Set model to training mode
    epoch_loss = 0.0

    for inputs, labels in train_loader:
        # Zero the gradients
        optimizer.zero_grad()

        # Move data to the same device as the model
        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)

        #print(type(inputs), inputs.shape)

        # Forward pass
        outputs = model_simple(inputs)

        #print(type(outputs[0]))
        # Compute the loss
        loss = criterion(outputs, labels)
        epoch_loss += loss.item()

        # Backward pass
        loss.backward()

        # Update weights
        optimizer.step()

    print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}")

    # Validation phase
    model_simple.eval()  # Set model to evaluation mode
    val_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():  # No gradients needed during validation
        for val_inputs, val_labels in val_loader:
            # Move data to the same device as the model
            val_inputs, val_labels = val_inputs.to(DEVICE), val_labels.to(DEVICE)

            # Forward pass
            val_outputs = model_simple(val_inputs)

            # Compute validation loss
            loss = criterion(val_outputs, val_labels)
            val_loss += loss.item()

            # Compute accuracy
            _, predicted = torch.max(val_outputs, 1)  # Get predicted class
            _, actual = torch.max(val_labels, 1)  # Get actual class (assuming one-hot labels)
            correct += (predicted == actual).sum().item()
            total += val_labels.size(0)

    val_accuracy = correct / total * 100
    print(f"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%")

print("Training complete!")

idx=1

transform_inference = transforms.Compose([
                transforms.Resize((500, 500)),     # Resize to 500x500
                transforms.ToTensor()              # Convert to Tensor (scales to [0, 1])
            ])

inference_dataset = HiDefDataset(root_dir=root_dir, transform = transform_inference)
image, mask = inference_dataset[idx]
logits_mask = model_simple(image.to(DEVICE).unsqueeze(0))
print(logits_mask)